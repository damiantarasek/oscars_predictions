{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Oscar Prediction with AutoML\n",
    "After out dataframe has been assemlbed (see scraping and table_assembling) notebooks we have the data we need to make predictions on the Best Picture winner. [AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html) represents a quick, but powerful route though the Machine Learning process. H2O's AutoML runs many models through the dataset and using cross-validation, picks the best one. For my purposes I use it to confirm/compare to the Preferential Balloting Random Forest model I created.\n",
    "If you are gunning to win your office's Oscar pool, scroll down to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Using h2o Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = pd.read_csv('./data/processed_results/osc_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_231\"; Java(TM) SE Runtime Environment (build 1.8.0_231-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.231-b11, mixed mode)\n",
      "  Starting server from /Users/nickparker/anaconda3/envs/DistributedComputing/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/kj/kg5zhyt51z7__kkfrysh9lv00000gn/T/tmp3o9mei8_\n",
      "  JVM stdout: /var/folders/kj/kg5zhyt51z7__kkfrysh9lv00000gn/T/tmp3o9mei8_/h2o_nickparker_started_from_python.out\n",
      "  JVM stderr: /var/folders/kj/kg5zhyt51z7__kkfrysh9lv00000gn/T/tmp3o9mei8_/h2o_nickparker_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>10 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_nickparker_u1frbb</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       America/Los_Angeles\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.0.2\n",
       "H2O cluster version age:    10 days\n",
       "H2O cluster name:           H2O_from_python_nickparker_u1frbb\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.4 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Year of Existance. This data will be used below\n",
    "- golden_globes 1943\n",
    "- pga 1989\n",
    "- bafta 1960\n",
    "- dga 1948\n",
    "- sag 1995\n",
    "- cannes 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pick a min_year where the awards shows will be relevant\n",
    "min_year = 1995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O's Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains: 159 movies\n"
     ]
    }
   ],
   "source": [
    "# Auto ML uses Cross Validation, so we do not specifiy a validation set\n",
    "train = full_table.loc[((full_table['year'] < 2019) & (full_table['year'] >= min_year))]\n",
    "\n",
    "print('training set contains:', train.shape[0], 'movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'year', 'film', 'wiki', 'winner', 'Nominations',\n",
       "       'Oscar_win', 'nom_gg_drama', 'winner_gg_drama', 'nom_gg_comedy',\n",
       "       'winner_gg_comedy', 'nom_pga', 'winner_pga', 'nom_bafta',\n",
       "       'winner_bafta', 'nom_dga', 'winner_dga', 'nom_sag', 'winner_sag',\n",
       "       'nom_cannes', 'winner_cannes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "AutoML progress: |███████████\n",
      "22:16:24.197: Skipping training of model GBM_5_AutoML_20200130_221603 due to exception: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for GBM model: GBM_5_AutoML_20200130_221603.  Details: ERRR on field: _min_rows: The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 159.0.\n",
      "\n",
      "\n",
      "█████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                            </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_32     </td><td style=\"text-align: right;\">0.884568</td><td style=\"text-align: right;\"> 0.361476</td><td style=\"text-align: right;\">0.406898 </td><td style=\"text-align: right;\">              0.211111</td><td style=\"text-align: right;\">0.329695</td><td style=\"text-align: right;\">0.108699 </td><td style=\"text-align: right;\">               430</td><td style=\"text-align: right;\">                 0.033521</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_36     </td><td style=\"text-align: right;\">0.880556</td><td style=\"text-align: right;\"> 0.361096</td><td style=\"text-align: right;\">0.413082 </td><td style=\"text-align: right;\">              0.124537</td><td style=\"text-align: right;\">0.330677</td><td style=\"text-align: right;\">0.109347 </td><td style=\"text-align: right;\">               433</td><td style=\"text-align: right;\">                 0.025117</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_22     </td><td style=\"text-align: right;\">0.879938</td><td style=\"text-align: right;\"> 0.367363</td><td style=\"text-align: right;\">0.402578 </td><td style=\"text-align: right;\">              0.197685</td><td style=\"text-align: right;\">0.331329</td><td style=\"text-align: right;\">0.109779 </td><td style=\"text-align: right;\">               357</td><td style=\"text-align: right;\">                 0.030058</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_21     </td><td style=\"text-align: right;\">0.875617</td><td style=\"text-align: right;\"> 0.341856</td><td style=\"text-align: right;\">0.401486 </td><td style=\"text-align: right;\">              0.197685</td><td style=\"text-align: right;\">0.333787</td><td style=\"text-align: right;\">0.111414 </td><td style=\"text-align: right;\">               300</td><td style=\"text-align: right;\">                 0.03741 </td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_1 </td><td style=\"text-align: right;\">0.857099</td><td style=\"text-align: right;\"> 1.00078 </td><td style=\"text-align: right;\">0.381509 </td><td style=\"text-align: right;\">              0.21713 </td><td style=\"text-align: right;\">0.314501</td><td style=\"text-align: right;\">0.0989112</td><td style=\"text-align: right;\">             17116</td><td style=\"text-align: right;\">                 0.223012</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_6      </td><td style=\"text-align: right;\">0.85679 </td><td style=\"text-align: right;\"> 0.440318</td><td style=\"text-align: right;\">0.0734754</td><td style=\"text-align: right;\">              0.176852</td><td style=\"text-align: right;\">0.364002</td><td style=\"text-align: right;\">0.132497 </td><td style=\"text-align: right;\">               195</td><td style=\"text-align: right;\">                 0.02522 </td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_10     </td><td style=\"text-align: right;\">0.850926</td><td style=\"text-align: right;\"> 0.348005</td><td style=\"text-align: right;\">0.386856 </td><td style=\"text-align: right;\">              0.228241</td><td style=\"text-align: right;\">0.335706</td><td style=\"text-align: right;\">0.112698 </td><td style=\"text-align: right;\">               167</td><td style=\"text-align: right;\">                 0.056153</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_13     </td><td style=\"text-align: right;\">0.846914</td><td style=\"text-align: right;\"> 0.428167</td><td style=\"text-align: right;\">0.0778886</td><td style=\"text-align: right;\">              0.176852</td><td style=\"text-align: right;\">0.357597</td><td style=\"text-align: right;\">0.127876 </td><td style=\"text-align: right;\">               136</td><td style=\"text-align: right;\">                 0.029801</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_19     </td><td style=\"text-align: right;\">0.842438</td><td style=\"text-align: right;\"> 0.433884</td><td style=\"text-align: right;\">0.0744927</td><td style=\"text-align: right;\">              0.176852</td><td style=\"text-align: right;\">0.360472</td><td style=\"text-align: right;\">0.12994  </td><td style=\"text-align: right;\">               122</td><td style=\"text-align: right;\">                 0.034516</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_15     </td><td style=\"text-align: right;\">0.84213 </td><td style=\"text-align: right;\"> 0.423558</td><td style=\"text-align: right;\">0.0813782</td><td style=\"text-align: right;\">              0.176852</td><td style=\"text-align: right;\">0.355679</td><td style=\"text-align: right;\">0.126508 </td><td style=\"text-align: right;\">               123</td><td style=\"text-align: right;\">                 0.032996</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_8      </td><td style=\"text-align: right;\">0.84213 </td><td style=\"text-align: right;\"> 0.421899</td><td style=\"text-align: right;\">0.0813782</td><td style=\"text-align: right;\">              0.176852</td><td style=\"text-align: right;\">0.354878</td><td style=\"text-align: right;\">0.125938 </td><td style=\"text-align: right;\">               143</td><td style=\"text-align: right;\">                 0.037386</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_9      </td><td style=\"text-align: right;\">0.834568</td><td style=\"text-align: right;\"> 0.37563 </td><td style=\"text-align: right;\">0.359651 </td><td style=\"text-align: right;\">              0.256481</td><td style=\"text-align: right;\">0.34984 </td><td style=\"text-align: right;\">0.122388 </td><td style=\"text-align: right;\">               151</td><td style=\"text-align: right;\">                 0.037774</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_12     </td><td style=\"text-align: right;\">0.833333</td><td style=\"text-align: right;\"> 0.365273</td><td style=\"text-align: right;\">0.364439 </td><td style=\"text-align: right;\">              0.243056</td><td style=\"text-align: right;\">0.344443</td><td style=\"text-align: right;\">0.118641 </td><td style=\"text-align: right;\">               184</td><td style=\"text-align: right;\">                 0.042611</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_23     </td><td style=\"text-align: right;\">0.832253</td><td style=\"text-align: right;\"> 0.435217</td><td style=\"text-align: right;\">0.0710157</td><td style=\"text-align: right;\">              0.176852</td><td style=\"text-align: right;\">0.360666</td><td style=\"text-align: right;\">0.13008  </td><td style=\"text-align: right;\">               131</td><td style=\"text-align: right;\">                 0.03197 </td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_5      </td><td style=\"text-align: right;\">0.823765</td><td style=\"text-align: right;\"> 0.387965</td><td style=\"text-align: right;\">0.335103 </td><td style=\"text-align: right;\">              0.254167</td><td style=\"text-align: right;\">0.35635 </td><td style=\"text-align: right;\">0.126986 </td><td style=\"text-align: right;\">               262</td><td style=\"text-align: right;\">                 0.02396 </td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_28     </td><td style=\"text-align: right;\">0.821142</td><td style=\"text-align: right;\"> 0.379587</td><td style=\"text-align: right;\">0.32654  </td><td style=\"text-align: right;\">              0.246759</td><td style=\"text-align: right;\">0.351886</td><td style=\"text-align: right;\">0.123823 </td><td style=\"text-align: right;\">               227</td><td style=\"text-align: right;\">                 0.023572</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_8 </td><td style=\"text-align: right;\">0.808333</td><td style=\"text-align: right;\"> 0.867949</td><td style=\"text-align: right;\">0.485079 </td><td style=\"text-align: right;\">              0.255093</td><td style=\"text-align: right;\">0.339222</td><td style=\"text-align: right;\">0.115072 </td><td style=\"text-align: right;\">             33956</td><td style=\"text-align: right;\">                 0.310137</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_2      </td><td style=\"text-align: right;\">0.80787 </td><td style=\"text-align: right;\"> 0.445896</td><td style=\"text-align: right;\">0.301899 </td><td style=\"text-align: right;\">              0.180093</td><td style=\"text-align: right;\">0.380677</td><td style=\"text-align: right;\">0.144915 </td><td style=\"text-align: right;\">               252</td><td style=\"text-align: right;\">                 0.032958</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_31     </td><td style=\"text-align: right;\">0.805556</td><td style=\"text-align: right;\"> 0.393052</td><td style=\"text-align: right;\">0.342282 </td><td style=\"text-align: right;\">              0.261574</td><td style=\"text-align: right;\">0.356703</td><td style=\"text-align: right;\">0.127237 </td><td style=\"text-align: right;\">               150</td><td style=\"text-align: right;\">                 0.022709</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_5 </td><td style=\"text-align: right;\">0.804321</td><td style=\"text-align: right;\"> 0.446539</td><td style=\"text-align: right;\">0.425572 </td><td style=\"text-align: right;\">              0.240741</td><td style=\"text-align: right;\">0.336011</td><td style=\"text-align: right;\">0.112903 </td><td style=\"text-align: right;\">              3057</td><td style=\"text-align: right;\">                 0.030371</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_1 </td><td style=\"text-align: right;\">0.798148</td><td style=\"text-align: right;\"> 0.592816</td><td style=\"text-align: right;\">0.351526 </td><td style=\"text-align: right;\">              0.194444</td><td style=\"text-align: right;\">0.374916</td><td style=\"text-align: right;\">0.140562 </td><td style=\"text-align: right;\">              7450</td><td style=\"text-align: right;\">                 0.027411</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_34     </td><td style=\"text-align: right;\">0.779938</td><td style=\"text-align: right;\"> 0.505303</td><td style=\"text-align: right;\">0.270395 </td><td style=\"text-align: right;\">              0.218056</td><td style=\"text-align: right;\">0.397023</td><td style=\"text-align: right;\">0.157627 </td><td style=\"text-align: right;\">               298</td><td style=\"text-align: right;\">                 0.022541</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_14     </td><td style=\"text-align: right;\">0.772531</td><td style=\"text-align: right;\"> 0.451947</td><td style=\"text-align: right;\">0.282041 </td><td style=\"text-align: right;\">              0.280093</td><td style=\"text-align: right;\">0.378142</td><td style=\"text-align: right;\">0.142992 </td><td style=\"text-align: right;\">               194</td><td style=\"text-align: right;\">                 0.036236</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_11</td><td style=\"text-align: right;\">0.771296</td><td style=\"text-align: right;\"> 0.457553</td><td style=\"text-align: right;\">0.360859 </td><td style=\"text-align: right;\">              0.287037</td><td style=\"text-align: right;\">0.347528</td><td style=\"text-align: right;\">0.120776 </td><td style=\"text-align: right;\">              3339</td><td style=\"text-align: right;\">                 0.033156</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_33     </td><td style=\"text-align: right;\">0.755247</td><td style=\"text-align: right;\"> 0.452186</td><td style=\"text-align: right;\">0.277281 </td><td style=\"text-align: right;\">              0.272685</td><td style=\"text-align: right;\">0.375538</td><td style=\"text-align: right;\">0.141029 </td><td style=\"text-align: right;\">               124</td><td style=\"text-align: right;\">                 0.027231</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_3 </td><td style=\"text-align: right;\">0.752778</td><td style=\"text-align: right;\"> 0.796506</td><td style=\"text-align: right;\">0.315565 </td><td style=\"text-align: right;\">              0.234722</td><td style=\"text-align: right;\">0.391936</td><td style=\"text-align: right;\">0.153614 </td><td style=\"text-align: right;\">              2763</td><td style=\"text-align: right;\">                 0.029036</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20200130_221603               </td><td style=\"text-align: right;\">0.750926</td><td style=\"text-align: right;\"> 0.523912</td><td style=\"text-align: right;\">0.259504 </td><td style=\"text-align: right;\">              0.257407</td><td style=\"text-align: right;\">0.401358</td><td style=\"text-align: right;\">0.161089 </td><td style=\"text-align: right;\">                70</td><td style=\"text-align: right;\">                 0.03394 </td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_11     </td><td style=\"text-align: right;\">0.750926</td><td style=\"text-align: right;\"> 0.425538</td><td style=\"text-align: right;\">0.261051 </td><td style=\"text-align: right;\">              0.296296</td><td style=\"text-align: right;\">0.3692  </td><td style=\"text-align: right;\">0.136308 </td><td style=\"text-align: right;\">               129</td><td style=\"text-align: right;\">                 0.034578</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_2 </td><td style=\"text-align: right;\">0.75    </td><td style=\"text-align: right;\"> 0.614542</td><td style=\"text-align: right;\">0.393203 </td><td style=\"text-align: right;\">              0.287037</td><td style=\"text-align: right;\">0.348305</td><td style=\"text-align: right;\">0.121316 </td><td style=\"text-align: right;\">              3867</td><td style=\"text-align: right;\">                 0.032028</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_4 </td><td style=\"text-align: right;\">0.742901</td><td style=\"text-align: right;\"> 1.28147 </td><td style=\"text-align: right;\">0.392714 </td><td style=\"text-align: right;\">              0.285648</td><td style=\"text-align: right;\">0.355456</td><td style=\"text-align: right;\">0.126349 </td><td style=\"text-align: right;\">              5165</td><td style=\"text-align: right;\">                 0.032462</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20200130_221603                        </td><td style=\"text-align: right;\">0.720525</td><td style=\"text-align: right;\"> 0.488674</td><td style=\"text-align: right;\">0.244945 </td><td style=\"text-align: right;\">              0.273611</td><td style=\"text-align: right;\">0.376204</td><td style=\"text-align: right;\">0.14153  </td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">                 0.022197</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20200130_221603                        </td><td style=\"text-align: right;\">0.716975</td><td style=\"text-align: right;\"> 0.510133</td><td style=\"text-align: right;\">0.227959 </td><td style=\"text-align: right;\">              0.257407</td><td style=\"text-align: right;\">0.384687</td><td style=\"text-align: right;\">0.147984 </td><td style=\"text-align: right;\">               149</td><td style=\"text-align: right;\">                 0.031805</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_8 </td><td style=\"text-align: right;\">0.693519</td><td style=\"text-align: right;\"> 0.778803</td><td style=\"text-align: right;\">0.256776 </td><td style=\"text-align: right;\">              0.297685</td><td style=\"text-align: right;\">0.399574</td><td style=\"text-align: right;\">0.159659 </td><td style=\"text-align: right;\">              2551</td><td style=\"text-align: right;\">                 0.031507</td></tr>\n",
       "<tr><td>GLM_1_AutoML_20200130_221603                        </td><td style=\"text-align: right;\">0.675617</td><td style=\"text-align: right;\"> 0.424222</td><td style=\"text-align: right;\">0.267282 </td><td style=\"text-align: right;\">              0.310648</td><td style=\"text-align: right;\">0.358131</td><td style=\"text-align: right;\">0.128258 </td><td style=\"text-align: right;\">                76</td><td style=\"text-align: right;\">                 0.023375</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_3 </td><td style=\"text-align: right;\">0.672531</td><td style=\"text-align: right;\"> 0.940498</td><td style=\"text-align: right;\">0.400075 </td><td style=\"text-align: right;\">              0.27963 </td><td style=\"text-align: right;\">0.354022</td><td style=\"text-align: right;\">0.125332 </td><td style=\"text-align: right;\">             21731</td><td style=\"text-align: right;\">                 0.230794</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_7 </td><td style=\"text-align: right;\">0.671605</td><td style=\"text-align: right;\"> 0.872796</td><td style=\"text-align: right;\">0.232554 </td><td style=\"text-align: right;\">              0.3625  </td><td style=\"text-align: right;\">0.39897 </td><td style=\"text-align: right;\">0.159177 </td><td style=\"text-align: right;\">              7877</td><td style=\"text-align: right;\">                 0.036503</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_20200130_221603                    </td><td style=\"text-align: right;\">0.669599</td><td style=\"text-align: right;\"> 0.45238 </td><td style=\"text-align: right;\">0.206317 </td><td style=\"text-align: right;\">              0.305556</td><td style=\"text-align: right;\">0.375516</td><td style=\"text-align: right;\">0.141012 </td><td style=\"text-align: right;\">               115</td><td style=\"text-align: right;\">                 0.023997</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_21         </td><td style=\"text-align: right;\">0.647222</td><td style=\"text-align: right;\"> 0.557995</td><td style=\"text-align: right;\">0.233674 </td><td style=\"text-align: right;\">              0.31713 </td><td style=\"text-align: right;\">0.384632</td><td style=\"text-align: right;\">0.147941 </td><td style=\"text-align: right;\">                59</td><td style=\"text-align: right;\">                 0.03351 </td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_12</td><td style=\"text-align: right;\">0.642284</td><td style=\"text-align: right;\"> 0.941855</td><td style=\"text-align: right;\">0.230901 </td><td style=\"text-align: right;\">              0.349074</td><td style=\"text-align: right;\">0.414628</td><td style=\"text-align: right;\">0.171916 </td><td style=\"text-align: right;\">              3894</td><td style=\"text-align: right;\">                 0.039391</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_2 </td><td style=\"text-align: right;\">0.641049</td><td style=\"text-align: right;\"> 0.804686</td><td style=\"text-align: right;\">0.282952 </td><td style=\"text-align: right;\">              0.330093</td><td style=\"text-align: right;\">0.376233</td><td style=\"text-align: right;\">0.141551 </td><td style=\"text-align: right;\">             22200</td><td style=\"text-align: right;\">                 0.100458</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_9 </td><td style=\"text-align: right;\">0.632716</td><td style=\"text-align: right;\"> 0.90953 </td><td style=\"text-align: right;\">0.22147  </td><td style=\"text-align: right;\">              0.346296</td><td style=\"text-align: right;\">0.409342</td><td style=\"text-align: right;\">0.16756  </td><td style=\"text-align: right;\">              2283</td><td style=\"text-align: right;\">                 0.06156 </td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_10</td><td style=\"text-align: right;\">0.624691</td><td style=\"text-align: right;\"> 1.19575 </td><td style=\"text-align: right;\">0.225055 </td><td style=\"text-align: right;\">              0.343981</td><td style=\"text-align: right;\">0.419651</td><td style=\"text-align: right;\">0.176107 </td><td style=\"text-align: right;\">              2667</td><td style=\"text-align: right;\">                 0.024084</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20200130_221603                        </td><td style=\"text-align: right;\">0.616358</td><td style=\"text-align: right;\"> 0.554422</td><td style=\"text-align: right;\">0.214971 </td><td style=\"text-align: right;\">              0.339352</td><td style=\"text-align: right;\">0.384727</td><td style=\"text-align: right;\">0.148015 </td><td style=\"text-align: right;\">               127</td><td style=\"text-align: right;\">                 0.019675</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_9 </td><td style=\"text-align: right;\">0.614506</td><td style=\"text-align: right;\"> 1.25298 </td><td style=\"text-align: right;\">0.190706 </td><td style=\"text-align: right;\">              0.375463</td><td style=\"text-align: right;\">0.422879</td><td style=\"text-align: right;\">0.178827 </td><td style=\"text-align: right;\">              2479</td><td style=\"text-align: right;\">                 0.027005</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20200130_221603                        </td><td style=\"text-align: right;\">0.605556</td><td style=\"text-align: right;\"> 0.547803</td><td style=\"text-align: right;\">0.202312 </td><td style=\"text-align: right;\">              0.349074</td><td style=\"text-align: right;\">0.383504</td><td style=\"text-align: right;\">0.147075 </td><td style=\"text-align: right;\">                43</td><td style=\"text-align: right;\">                 0.025025</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20200130_221603                        </td><td style=\"text-align: right;\">0.604938</td><td style=\"text-align: right;\"> 0.541022</td><td style=\"text-align: right;\">0.20257  </td><td style=\"text-align: right;\">              0.347685</td><td style=\"text-align: right;\">0.380167</td><td style=\"text-align: right;\">0.144527 </td><td style=\"text-align: right;\">               124</td><td style=\"text-align: right;\">                 0.028663</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_7          </td><td style=\"text-align: right;\">0.604321</td><td style=\"text-align: right;\"> 0.562388</td><td style=\"text-align: right;\">0.21621  </td><td style=\"text-align: right;\">              0.344444</td><td style=\"text-align: right;\">0.387347</td><td style=\"text-align: right;\">0.150038 </td><td style=\"text-align: right;\">                56</td><td style=\"text-align: right;\">                 0.027683</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_4 </td><td style=\"text-align: right;\">0.601235</td><td style=\"text-align: right;\"> 0.968462</td><td style=\"text-align: right;\">0.213398 </td><td style=\"text-align: right;\">              0.343519</td><td style=\"text-align: right;\">0.414867</td><td style=\"text-align: right;\">0.172115 </td><td style=\"text-align: right;\">              3867</td><td style=\"text-align: right;\">                 0.022999</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_25     </td><td style=\"text-align: right;\">0.589969</td><td style=\"text-align: right;\"> 0.452165</td><td style=\"text-align: right;\">0.173258 </td><td style=\"text-align: right;\">              0.3375  </td><td style=\"text-align: right;\">0.373325</td><td style=\"text-align: right;\">0.139372 </td><td style=\"text-align: right;\">               106</td><td style=\"text-align: right;\">                 0.018376</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_10</td><td style=\"text-align: right;\">0.584259</td><td style=\"text-align: right;\"> 1.20992 </td><td style=\"text-align: right;\">0.1946   </td><td style=\"text-align: right;\">              0.433333</td><td style=\"text-align: right;\">0.428109</td><td style=\"text-align: right;\">0.183277 </td><td style=\"text-align: right;\">              2829</td><td style=\"text-align: right;\">                 0.033615</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_2          </td><td style=\"text-align: right;\">0.564352</td><td style=\"text-align: right;\"> 2.35405 </td><td style=\"text-align: right;\">0.169883 </td><td style=\"text-align: right;\">              0.401389</td><td style=\"text-align: right;\">0.441778</td><td style=\"text-align: right;\">0.195168 </td><td style=\"text-align: right;\">                67</td><td style=\"text-align: right;\">                 0.028774</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20200130_221603                        </td><td style=\"text-align: right;\">0.555864</td><td style=\"text-align: right;\"> 0.761813</td><td style=\"text-align: right;\">0.163236 </td><td style=\"text-align: right;\">              0.355556</td><td style=\"text-align: right;\">0.407056</td><td style=\"text-align: right;\">0.165694 </td><td style=\"text-align: right;\">               109</td><td style=\"text-align: right;\">                 0.026104</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_6 </td><td style=\"text-align: right;\">0.549691</td><td style=\"text-align: right;\"> 0.87067 </td><td style=\"text-align: right;\">0.18577  </td><td style=\"text-align: right;\">              0.41713 </td><td style=\"text-align: right;\">0.411946</td><td style=\"text-align: right;\">0.169699 </td><td style=\"text-align: right;\">              2236</td><td style=\"text-align: right;\">                 0.024994</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_5 </td><td style=\"text-align: right;\">0.538272</td><td style=\"text-align: right;\"> 2.79062 </td><td style=\"text-align: right;\">0.221186 </td><td style=\"text-align: right;\">              0.377778</td><td style=\"text-align: right;\">0.392655</td><td style=\"text-align: right;\">0.154178 </td><td style=\"text-align: right;\">             30799</td><td style=\"text-align: right;\">                 0.519877</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_30     </td><td style=\"text-align: right;\">0.520216</td><td style=\"text-align: right;\"> 0.43938 </td><td style=\"text-align: right;\">0.136018 </td><td style=\"text-align: right;\">              0.313426</td><td style=\"text-align: right;\">0.367072</td><td style=\"text-align: right;\">0.134742 </td><td style=\"text-align: right;\">               137</td><td style=\"text-align: right;\">                 0.019652</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_11</td><td style=\"text-align: right;\">0.516667</td><td style=\"text-align: right;\"> 1.89293 </td><td style=\"text-align: right;\">0.154832 </td><td style=\"text-align: right;\">              0.402315</td><td style=\"text-align: right;\">0.410462</td><td style=\"text-align: right;\">0.168479 </td><td style=\"text-align: right;\">             16035</td><td style=\"text-align: right;\">                 0.090872</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_11</td><td style=\"text-align: right;\">0.512654</td><td style=\"text-align: right;\"> 1.85657 </td><td style=\"text-align: right;\">0.203178 </td><td style=\"text-align: right;\">              0.393981</td><td style=\"text-align: right;\">0.414008</td><td style=\"text-align: right;\">0.171403 </td><td style=\"text-align: right;\">              8380</td><td style=\"text-align: right;\">                 0.12416 </td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_1 </td><td style=\"text-align: right;\">0.509259</td><td style=\"text-align: right;\"> 2.20225 </td><td style=\"text-align: right;\">0.206392 </td><td style=\"text-align: right;\">              0.394907</td><td style=\"text-align: right;\">0.393809</td><td style=\"text-align: right;\">0.155085 </td><td style=\"text-align: right;\">             47639</td><td style=\"text-align: right;\">                 0.488816</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_7 </td><td style=\"text-align: right;\">0.50463 </td><td style=\"text-align: right;\"> 1.48305 </td><td style=\"text-align: right;\">0.323224 </td><td style=\"text-align: right;\">              0.366667</td><td style=\"text-align: right;\">0.359797</td><td style=\"text-align: right;\">0.129454 </td><td style=\"text-align: right;\">              5034</td><td style=\"text-align: right;\">                 0.028514</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_3 </td><td style=\"text-align: right;\">0.499383</td><td style=\"text-align: right;\"> 1.5713  </td><td style=\"text-align: right;\">0.170305 </td><td style=\"text-align: right;\">              0.485185</td><td style=\"text-align: right;\">0.40757 </td><td style=\"text-align: right;\">0.166113 </td><td style=\"text-align: right;\">             37074</td><td style=\"text-align: right;\">                 0.508685</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_9 </td><td style=\"text-align: right;\">0.485802</td><td style=\"text-align: right;\"> 1.44225 </td><td style=\"text-align: right;\">0.153652 </td><td style=\"text-align: right;\">              0.425926</td><td style=\"text-align: right;\">0.420317</td><td style=\"text-align: right;\">0.176666 </td><td style=\"text-align: right;\">              3921</td><td style=\"text-align: right;\">                 0.028929</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_23         </td><td style=\"text-align: right;\">0.482099</td><td style=\"text-align: right;\"> 1.63398 </td><td style=\"text-align: right;\">0.149987 </td><td style=\"text-align: right;\">              0.447222</td><td style=\"text-align: right;\">0.437471</td><td style=\"text-align: right;\">0.191381 </td><td style=\"text-align: right;\">                30</td><td style=\"text-align: right;\">                 0.023941</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_4 </td><td style=\"text-align: right;\">0.455247</td><td style=\"text-align: right;\"> 1.41996 </td><td style=\"text-align: right;\">0.149685 </td><td style=\"text-align: right;\">              0.433333</td><td style=\"text-align: right;\">0.406443</td><td style=\"text-align: right;\">0.165196 </td><td style=\"text-align: right;\">              3831</td><td style=\"text-align: right;\">                 0.05529 </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_15         </td><td style=\"text-align: right;\">0.44784 </td><td style=\"text-align: right;\"> 0.646619</td><td style=\"text-align: right;\">0.154095 </td><td style=\"text-align: right;\">              0.403704</td><td style=\"text-align: right;\">0.403653</td><td style=\"text-align: right;\">0.162936 </td><td style=\"text-align: right;\">                58</td><td style=\"text-align: right;\">                 0.029202</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_29     </td><td style=\"text-align: right;\">0.440432</td><td style=\"text-align: right;\"> 0.458942</td><td style=\"text-align: right;\">0.118223 </td><td style=\"text-align: right;\">              0.371296</td><td style=\"text-align: right;\">0.374224</td><td style=\"text-align: right;\">0.140044 </td><td style=\"text-align: right;\">               129</td><td style=\"text-align: right;\">                 0.018909</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_5          </td><td style=\"text-align: right;\">0.427778</td><td style=\"text-align: right;\"> 0.590142</td><td style=\"text-align: right;\">0.160662 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.393912</td><td style=\"text-align: right;\">0.155167 </td><td style=\"text-align: right;\">                30</td><td style=\"text-align: right;\">                 0.027658</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_19         </td><td style=\"text-align: right;\">0.421914</td><td style=\"text-align: right;\"> 3.1611  </td><td style=\"text-align: right;\">0.144788 </td><td style=\"text-align: right;\">              0.365278</td><td style=\"text-align: right;\">0.413271</td><td style=\"text-align: right;\">0.170793 </td><td style=\"text-align: right;\">                25</td><td style=\"text-align: right;\">                 0.025403</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_6 </td><td style=\"text-align: right;\">0.405864</td><td style=\"text-align: right;\"> 1.67729 </td><td style=\"text-align: right;\">0.152599 </td><td style=\"text-align: right;\">              0.411111</td><td style=\"text-align: right;\">0.37975 </td><td style=\"text-align: right;\">0.14421  </td><td style=\"text-align: right;\">              6903</td><td style=\"text-align: right;\">                 0.039172</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_12         </td><td style=\"text-align: right;\">0.400926</td><td style=\"text-align: right;\"> 0.474762</td><td style=\"text-align: right;\">0.166313 </td><td style=\"text-align: right;\">              0.468056</td><td style=\"text-align: right;\">0.367046</td><td style=\"text-align: right;\">0.134723 </td><td style=\"text-align: right;\">                67</td><td style=\"text-align: right;\">                 0.032056</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_5 </td><td style=\"text-align: right;\">0.398765</td><td style=\"text-align: right;\"> 3.66775 </td><td style=\"text-align: right;\">0.151001 </td><td style=\"text-align: right;\">              0.419444</td><td style=\"text-align: right;\">0.419539</td><td style=\"text-align: right;\">0.176013 </td><td style=\"text-align: right;\">             10812</td><td style=\"text-align: right;\">                 0.291961</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_20     </td><td style=\"text-align: right;\">0.3875  </td><td style=\"text-align: right;\"> 0.494125</td><td style=\"text-align: right;\">0.1169   </td><td style=\"text-align: right;\">              0.392593</td><td style=\"text-align: right;\">0.384734</td><td style=\"text-align: right;\">0.148021 </td><td style=\"text-align: right;\">               104</td><td style=\"text-align: right;\">                 0.016715</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_7 </td><td style=\"text-align: right;\">0.382407</td><td style=\"text-align: right;\"> 1.1012  </td><td style=\"text-align: right;\">0.149037 </td><td style=\"text-align: right;\">              0.422222</td><td style=\"text-align: right;\">0.378779</td><td style=\"text-align: right;\">0.143473 </td><td style=\"text-align: right;\">              7968</td><td style=\"text-align: right;\">                 0.032243</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_9          </td><td style=\"text-align: right;\">0.369753</td><td style=\"text-align: right;\"> 1.08935 </td><td style=\"text-align: right;\">0.129727 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.421441</td><td style=\"text-align: right;\">0.177613 </td><td style=\"text-align: right;\">                28</td><td style=\"text-align: right;\">                 0.027303</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200130_221603_model_10</td><td style=\"text-align: right;\">0.366358</td><td style=\"text-align: right;\"> 1.2153  </td><td style=\"text-align: right;\">0.127903 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.419795</td><td style=\"text-align: right;\">0.176228 </td><td style=\"text-align: right;\">              3958</td><td style=\"text-align: right;\">                 0.025421</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_16     </td><td style=\"text-align: right;\">0.358951</td><td style=\"text-align: right;\"> 0.491665</td><td style=\"text-align: right;\">0.111532 </td><td style=\"text-align: right;\">              0.407407</td><td style=\"text-align: right;\">0.383997</td><td style=\"text-align: right;\">0.147454 </td><td style=\"text-align: right;\">                84</td><td style=\"text-align: right;\">                 0.017813</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_2 </td><td style=\"text-align: right;\">0.35463 </td><td style=\"text-align: right;\"> 1.5254  </td><td style=\"text-align: right;\">0.1366   </td><td style=\"text-align: right;\">              0.492593</td><td style=\"text-align: right;\">0.41591 </td><td style=\"text-align: right;\">0.172981 </td><td style=\"text-align: right;\">             16989</td><td style=\"text-align: right;\">                 0.056034</td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20200130_221603                    </td><td style=\"text-align: right;\">0.352778</td><td style=\"text-align: right;\"> 0.496635</td><td style=\"text-align: right;\">0.109317 </td><td style=\"text-align: right;\">              0.388889</td><td style=\"text-align: right;\">0.386576</td><td style=\"text-align: right;\">0.149441 </td><td style=\"text-align: right;\">               633</td><td style=\"text-align: right;\">                 0.041683</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200130_221603_model_6 </td><td style=\"text-align: right;\">0.344444</td><td style=\"text-align: right;\"> 1.29477 </td><td style=\"text-align: right;\">0.120038 </td><td style=\"text-align: right;\">              0.422222</td><td style=\"text-align: right;\">0.387728</td><td style=\"text-align: right;\">0.150333 </td><td style=\"text-align: right;\">              4918</td><td style=\"text-align: right;\">                 0.033927</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200130_221603_model_8 </td><td style=\"text-align: right;\">0.295062</td><td style=\"text-align: right;\"> 3.23607 </td><td style=\"text-align: right;\">0.129695 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.434253</td><td style=\"text-align: right;\">0.188575 </td><td style=\"text-align: right;\">             68046</td><td style=\"text-align: right;\">                 0.464042</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_11         </td><td style=\"text-align: right;\">0.289506</td><td style=\"text-align: right;\"> 0.653528</td><td style=\"text-align: right;\">0.10315  </td><td style=\"text-align: right;\">              0.496296</td><td style=\"text-align: right;\">0.407082</td><td style=\"text-align: right;\">0.165716 </td><td style=\"text-align: right;\">                29</td><td style=\"text-align: right;\">                 0.018957</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_18         </td><td style=\"text-align: right;\">0.276235</td><td style=\"text-align: right;\"> 0.512228</td><td style=\"text-align: right;\">0.148783 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.376144</td><td style=\"text-align: right;\">0.141485 </td><td style=\"text-align: right;\">                44</td><td style=\"text-align: right;\">                 0.02724 </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_6          </td><td style=\"text-align: right;\">0.27284 </td><td style=\"text-align: right;\"> 0.531716</td><td style=\"text-align: right;\">0.125963 </td><td style=\"text-align: right;\">              0.485185</td><td style=\"text-align: right;\">0.382902</td><td style=\"text-align: right;\">0.146614 </td><td style=\"text-align: right;\">                33</td><td style=\"text-align: right;\">                 0.024106</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_14         </td><td style=\"text-align: right;\">0.254012</td><td style=\"text-align: right;\"> 0.54289 </td><td style=\"text-align: right;\">0.107173 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.385194</td><td style=\"text-align: right;\">0.148374 </td><td style=\"text-align: right;\">                38</td><td style=\"text-align: right;\">                 0.02407 </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_3          </td><td style=\"text-align: right;\">0.241049</td><td style=\"text-align: right;\"> 0.545718</td><td style=\"text-align: right;\">0.12067  </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.383187</td><td style=\"text-align: right;\">0.146833 </td><td style=\"text-align: right;\">                28</td><td style=\"text-align: right;\">                 0.026282</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_16         </td><td style=\"text-align: right;\">0.23858 </td><td style=\"text-align: right;\"> 0.550656</td><td style=\"text-align: right;\">0.126654 </td><td style=\"text-align: right;\">              0.496296</td><td style=\"text-align: right;\">0.382452</td><td style=\"text-align: right;\">0.14627  </td><td style=\"text-align: right;\">                56</td><td style=\"text-align: right;\">                 0.030113</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_10         </td><td style=\"text-align: right;\">0.221296</td><td style=\"text-align: right;\"> 0.565968</td><td style=\"text-align: right;\">0.106611 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.387955</td><td style=\"text-align: right;\">0.150509 </td><td style=\"text-align: right;\">                26</td><td style=\"text-align: right;\">                 0.029367</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_8          </td><td style=\"text-align: right;\">0.199383</td><td style=\"text-align: right;\"> 0.554229</td><td style=\"text-align: right;\">0.0920024</td><td style=\"text-align: right;\">              0.496296</td><td style=\"text-align: right;\">0.388543</td><td style=\"text-align: right;\">0.150965 </td><td style=\"text-align: right;\">                26</td><td style=\"text-align: right;\">                 0.064396</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_4          </td><td style=\"text-align: right;\">0.196914</td><td style=\"text-align: right;\"> 0.622953</td><td style=\"text-align: right;\">0.0942809</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.401352</td><td style=\"text-align: right;\">0.161084 </td><td style=\"text-align: right;\">                20</td><td style=\"text-align: right;\">                 0.024654</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200130_221603_model_27         </td><td style=\"text-align: right;\">0.190586</td><td style=\"text-align: right;\"> 0.559509</td><td style=\"text-align: right;\">0.0899345</td><td style=\"text-align: right;\">              0.492593</td><td style=\"text-align: right;\">0.389571</td><td style=\"text-align: right;\">0.151766 </td><td style=\"text-align: right;\">                15</td><td style=\"text-align: right;\">                 0.034432</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_18     </td><td style=\"text-align: right;\">0.174074</td><td style=\"text-align: right;\"> 0.49066 </td><td style=\"text-align: right;\">0.0855795</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.380089</td><td style=\"text-align: right;\">0.144468 </td><td style=\"text-align: right;\">               164</td><td style=\"text-align: right;\">                 0.021573</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_3      </td><td style=\"text-align: right;\">0.169136</td><td style=\"text-align: right;\"> 0.504776</td><td style=\"text-align: right;\">0.0890733</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.382919</td><td style=\"text-align: right;\">0.146627 </td><td style=\"text-align: right;\">               145</td><td style=\"text-align: right;\">                 0.04961 </td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_35     </td><td style=\"text-align: right;\">0.15787 </td><td style=\"text-align: right;\"> 0.497312</td><td style=\"text-align: right;\">0.0824538</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.380767</td><td style=\"text-align: right;\">0.144983 </td><td style=\"text-align: right;\">               120</td><td style=\"text-align: right;\">                 0.139155</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_24     </td><td style=\"text-align: right;\">0.15787 </td><td style=\"text-align: right;\"> 0.497193</td><td style=\"text-align: right;\">0.0824538</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.380446</td><td style=\"text-align: right;\">0.144739 </td><td style=\"text-align: right;\">               108</td><td style=\"text-align: right;\">                 0.053908</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_27     </td><td style=\"text-align: right;\">0.157562</td><td style=\"text-align: right;\"> 0.501308</td><td style=\"text-align: right;\">0.0824328</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.381247</td><td style=\"text-align: right;\">0.14535  </td><td style=\"text-align: right;\">               103</td><td style=\"text-align: right;\">                 0.023152</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_26     </td><td style=\"text-align: right;\">0.157562</td><td style=\"text-align: right;\"> 0.504286</td><td style=\"text-align: right;\">0.0822152</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.381744</td><td style=\"text-align: right;\">0.145728 </td><td style=\"text-align: right;\">                98</td><td style=\"text-align: right;\">                 0.020518</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_17     </td><td style=\"text-align: right;\">0.157562</td><td style=\"text-align: right;\"> 0.457869</td><td style=\"text-align: right;\">0.0824328</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.370396</td><td style=\"text-align: right;\">0.137193 </td><td style=\"text-align: right;\">                79</td><td style=\"text-align: right;\">                 0.019531</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_4      </td><td style=\"text-align: right;\">0.157562</td><td style=\"text-align: right;\"> 0.496781</td><td style=\"text-align: right;\">0.0822152</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.381227</td><td style=\"text-align: right;\">0.145334 </td><td style=\"text-align: right;\">                96</td><td style=\"text-align: right;\">                 0.020499</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_1      </td><td style=\"text-align: right;\">0.157562</td><td style=\"text-align: right;\"> 0.494575</td><td style=\"text-align: right;\">0.0824328</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.381013</td><td style=\"text-align: right;\">0.145171 </td><td style=\"text-align: right;\">               154</td><td style=\"text-align: right;\">                 0.021304</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20200130_221603                    </td><td style=\"text-align: right;\">0.156636</td><td style=\"text-align: right;\"> 0.494736</td><td style=\"text-align: right;\">0.0832873</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.379454</td><td style=\"text-align: right;\">0.143985 </td><td style=\"text-align: right;\">               203</td><td style=\"text-align: right;\">                 0.020685</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20200130_221603_model_7      </td><td style=\"text-align: right;\">0.112191</td><td style=\"text-align: right;\"> 0.505495</td><td style=\"text-align: right;\">0.0814521</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.382963</td><td style=\"text-align: right;\">0.14666  </td><td style=\"text-align: right;\">                96</td><td style=\"text-align: right;\">                 0.020756</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import H2OAutoML, get_leaderboard\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train = h2o.H2OFrame(train)\n",
    "\n",
    "# Identify predictors and response\n",
    "predictors = ['year','nom_gg_drama', 'winner_gg_drama', 'nom_gg_comedy', 'winner_gg_comedy',\n",
    "       'nom_pga', 'winner_pga', 'nom_bafta', 'winner_bafta', 'nom_dga', 'winner_dga',\n",
    "        'nom_sag', 'winner_sag', 'nom_cannes', 'winner_cannes','Nominations']\n",
    "\n",
    "x = predictors\n",
    "y = 'Oscar_win'\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "\n",
    "# Run AutoML for 100 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=100, seed=1\n",
    "                , keep_cross_validation_predictions= True\n",
    "               , exclude_algos = ['StackedEnsemble'])\n",
    "\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "\n",
    "# Optionally edd extra model information to the leaderboard\n",
    "lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "\n",
    "# Print all rows (instead of default 10 rows)\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OXGBoostEstimator :  XGBoost\n",
      "Model Key:  XGBoost_grid__1_AutoML_20200130_221603_model_32\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees\n",
       "0              183.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.07864349634776278\n",
      "RMSE: 0.28043447781569725\n",
      "LogLoss: 0.2904010718951874\n",
      "Mean Per-Class Error: 0.08749999999999991\n",
      "AUC: 0.9583333333333334\n",
      "AUCPR: 0.785851912395023\n",
      "Gini: 0.9166666666666667\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3950708508491516: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.037</td>\n",
       "      <td>(5.0/135.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>(6.0/24.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>136.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>(11.0/159.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1   Error           Rate\n",
       "0      0  130.0   5.0   0.037    (5.0/135.0)\n",
       "1      1    6.0  18.0    0.25     (6.0/24.0)\n",
       "2  Total  136.0  23.0  0.0692   (11.0/159.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.395071</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.190715</td>\n",
       "      <td>0.839416</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.540660</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.395071</td>\n",
       "      <td>0.930818</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.579348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.137821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.579348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.395071</td>\n",
       "      <td>0.725615</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.200891</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.190715</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.579348</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.579348</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.137821</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.579348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.579348</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.137821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold       value   idx\n",
       "0                        max f1   0.395071    0.765957  21.0\n",
       "1                        max f2   0.190715    0.839416  37.0\n",
       "2                  max f0point5   0.540660    0.808824  10.0\n",
       "3                  max accuracy   0.395071    0.930818  21.0\n",
       "4                 max precision   0.579348    1.000000   0.0\n",
       "5                    max recall   0.137821    1.000000  50.0\n",
       "6               max specificity   0.579348    1.000000   0.0\n",
       "7              max absolute_mcc   0.395071    0.725615  21.0\n",
       "8    max min_per_class_accuracy   0.200891    0.866667  36.0\n",
       "9   max mean_per_class_accuracy   0.190715    0.912500  37.0\n",
       "10                      max tns   0.579348  135.000000   0.0\n",
       "11                      max fns   0.579348   23.000000   0.0\n",
       "12                      max fps   0.127659  135.000000  62.0\n",
       "13                      max tps   0.137821   24.000000  50.0\n",
       "14                      max tnr   0.579348    1.000000   0.0\n",
       "15                      max fnr   0.579348    0.958333   0.0\n",
       "16                      max fpr   0.127659    1.000000  62.0\n",
       "17                      max tpr   0.137821    1.000000  50.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 15.09 %, avg score: 20.66 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.575728</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.577652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577652</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>562.50000</td>\n",
       "      <td>562.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0.575448</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.575514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576583</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>562.50000</td>\n",
       "      <td>562.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.031447</td>\n",
       "      <td>0.573447</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.575357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576338</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>562.50000</td>\n",
       "      <td>562.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.044025</td>\n",
       "      <td>0.562926</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.569441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.574367</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>562.50000</td>\n",
       "      <td>562.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.050314</td>\n",
       "      <td>0.547121</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.556169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.572093</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>562.50000</td>\n",
       "      <td>562.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.100629</td>\n",
       "      <td>0.489320</td>\n",
       "      <td>4.140625</td>\n",
       "      <td>5.382812</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.529377</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.550735</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>314.06250</td>\n",
       "      <td>438.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.393864</td>\n",
       "      <td>4.140625</td>\n",
       "      <td>4.968750</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.428525</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.509998</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>314.06250</td>\n",
       "      <td>396.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.201258</td>\n",
       "      <td>0.283238</td>\n",
       "      <td>1.656250</td>\n",
       "      <td>4.140625</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.362570</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.473141</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>65.62500</td>\n",
       "      <td>314.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.242188</td>\n",
       "      <td>3.174479</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.200496</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.382259</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>24.21875</td>\n",
       "      <td>217.447917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.402516</td>\n",
       "      <td>0.134404</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>2.484375</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.147325</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.323526</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-58.59375</td>\n",
       "      <td>148.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.128084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.472222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.128161</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.243933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>47.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.206637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.012579         0.575728  6.625000   \n",
       "1         2                  0.025157         0.575448  6.625000   \n",
       "2         3                  0.031447         0.573447  6.625000   \n",
       "3         4                  0.044025         0.562926  6.625000   \n",
       "4         5                  0.050314         0.547121  6.625000   \n",
       "5         6                  0.100629         0.489320  4.140625   \n",
       "6         7                  0.150943         0.393864  4.140625   \n",
       "7         8                  0.201258         0.283238  1.656250   \n",
       "8         9                  0.301887         0.187945  1.242188   \n",
       "9        10                  0.402516         0.134404  0.414062   \n",
       "10       11                  0.679245         0.128084  0.000000   \n",
       "11       12                  1.000000         0.127659  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          6.625000         1.0000  0.577652                  1.000000   \n",
       "1          6.625000         1.0000  0.575514                  1.000000   \n",
       "2          6.625000         1.0000  0.575357                  1.000000   \n",
       "3          6.625000         1.0000  0.569441                  1.000000   \n",
       "4          6.625000         1.0000  0.556169                  1.000000   \n",
       "5          5.382812         0.6250  0.529377                  0.812500   \n",
       "6          4.968750         0.6250  0.428525                  0.750000   \n",
       "7          4.140625         0.2500  0.362570                  0.625000   \n",
       "8          3.174479         0.1875  0.200496                  0.479167   \n",
       "9          2.484375         0.0625  0.147325                  0.375000   \n",
       "10         1.472222         0.0000  0.128161                  0.222222   \n",
       "11         1.000000         0.0000  0.127659                  0.150943   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           0.577652      0.083333                 0.083333  562.50000   \n",
       "1           0.576583      0.083333                 0.166667  562.50000   \n",
       "2           0.576338      0.041667                 0.208333  562.50000   \n",
       "3           0.574367      0.083333                 0.291667  562.50000   \n",
       "4           0.572093      0.041667                 0.333333  562.50000   \n",
       "5           0.550735      0.208333                 0.541667  314.06250   \n",
       "6           0.509998      0.208333                 0.750000  314.06250   \n",
       "7           0.473141      0.083333                 0.833333   65.62500   \n",
       "8           0.382259      0.125000                 0.958333   24.21875   \n",
       "9           0.323526      0.041667                 1.000000  -58.59375   \n",
       "10          0.243933      0.000000                 1.000000 -100.00000   \n",
       "11          0.206637      0.000000                 1.000000 -100.00000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0        562.500000  \n",
       "1        562.500000  \n",
       "2        562.500000  \n",
       "3        562.500000  \n",
       "4        562.500000  \n",
       "5        438.281250  \n",
       "6        396.875000  \n",
       "7        314.062500  \n",
       "8        217.447917  \n",
       "9        148.437500  \n",
       "10        47.222222  \n",
       "11         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.10869907561597124\n",
      "RMSE: 0.32969542856395695\n",
      "LogLoss: 0.3614764358814088\n",
      "Mean Per-Class Error: 0.124537037037037\n",
      "AUC: 0.884567901234568\n",
      "AUCPR: 0.406897908736144\n",
      "Gini: 0.7691358024691359\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.32207661867141724: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>(12.0/135.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>(8.0/24.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>131.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>(20.0/159.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1   Error           Rate\n",
       "0      0  123.0  12.0  0.0889   (12.0/135.0)\n",
       "1      1    8.0  16.0  0.3333     (8.0/24.0)\n",
       "2  Total  131.0  28.0  0.1258   (20.0/159.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.322077</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.303347</td>\n",
       "      <td>0.782313</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.322077</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.351293</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.583463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.150674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.583463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.303347</td>\n",
       "      <td>0.575934</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.303347</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.303347</td>\n",
       "      <td>0.875463</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.583463</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.583463</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.116664</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.150674</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.583463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.583463</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.116664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.150674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold       value   idx\n",
       "0                        max f1   0.322077    0.615385  18.0\n",
       "1                        max f2   0.303347    0.782313  21.0\n",
       "2                  max f0point5   0.322077    0.588235  18.0\n",
       "3                  max accuracy   0.351293    0.874214  16.0\n",
       "4                 max precision   0.583463    1.000000   0.0\n",
       "5                    max recall   0.150674    1.000000  49.0\n",
       "6               max specificity   0.583463    1.000000   0.0\n",
       "7              max absolute_mcc   0.303347    0.575934  21.0\n",
       "8    max min_per_class_accuracy   0.303347    0.792593  21.0\n",
       "9   max mean_per_class_accuracy   0.303347    0.875463  21.0\n",
       "10                      max tns   0.583463  135.000000   0.0\n",
       "11                      max fns   0.583463   23.000000   0.0\n",
       "12                      max fps   0.116664  135.000000  70.0\n",
       "13                      max tps   0.150674   24.000000  49.0\n",
       "14                      max tnr   0.583463    1.000000   0.0\n",
       "15                      max fnr   0.583463    0.958333   0.0\n",
       "16                      max fpr   0.116664    1.000000  70.0\n",
       "17                      max tpr   0.150674    1.000000  49.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 15.09 %, avg score: 22.18 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.572300</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583167</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583167</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>231.250000</td>\n",
       "      <td>231.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0.547586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.656250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556765</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.569966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>65.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.031447</td>\n",
       "      <td>0.538334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540764</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.564126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>32.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.044025</td>\n",
       "      <td>0.519089</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>1.892857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.536546</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.556246</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>231.250000</td>\n",
       "      <td>89.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.050314</td>\n",
       "      <td>0.457199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.656250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483975</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.547212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>65.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.353350</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>2.576389</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.401219</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.466105</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>231.250000</td>\n",
       "      <td>157.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.163522</td>\n",
       "      <td>0.351293</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>3.822115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351293</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.430778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>562.500000</td>\n",
       "      <td>282.211538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.303347</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.987745</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.306110</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.369667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>198.774510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.402516</td>\n",
       "      <td>0.218466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.380859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237066</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.342732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>138.085938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.534591</td>\n",
       "      <td>0.157106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.792647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164592</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.298721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>79.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.149780</td>\n",
       "      <td>0.473214</td>\n",
       "      <td>1.606061</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.150587</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.277773</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-52.678571</td>\n",
       "      <td>60.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.144069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.432432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149361</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.263890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>43.243243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.817610</td>\n",
       "      <td>0.124662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130714</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.244426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>22.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.899371</td>\n",
       "      <td>0.122491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123988</td>\n",
       "      <td>0.167832</td>\n",
       "      <td>0.233477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.188811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117067</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.221763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.012579         0.572300  3.312500   \n",
       "1         2                  0.025157         0.547586  0.000000   \n",
       "2         3                  0.031447         0.538334  0.000000   \n",
       "3         4                  0.044025         0.519089  3.312500   \n",
       "4         5                  0.050314         0.457199  0.000000   \n",
       "5         6                  0.113208         0.353350  3.312500   \n",
       "6         7                  0.163522         0.351293  6.625000   \n",
       "7         8                  0.320755         0.303347  2.120000   \n",
       "8         9                  0.402516         0.218466  0.000000   \n",
       "9        10                  0.534591         0.157106  0.000000   \n",
       "10       11                  0.622642         0.149780  0.473214   \n",
       "11       12                  0.698113         0.144069  0.000000   \n",
       "12       13                  0.817610         0.124662  0.000000   \n",
       "13       14                  0.899371         0.122491  0.000000   \n",
       "14       15                  1.000000         0.116664  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          3.312500       0.500000  0.583167                  0.500000   \n",
       "1          1.656250       0.000000  0.556765                  0.250000   \n",
       "2          1.325000       0.000000  0.540764                  0.200000   \n",
       "3          1.892857       0.500000  0.536546                  0.285714   \n",
       "4          1.656250       0.000000  0.483975                  0.250000   \n",
       "5          2.576389       0.500000  0.401219                  0.388889   \n",
       "6          3.822115       1.000000  0.351293                  0.576923   \n",
       "7          2.987745       0.320000  0.306110                  0.450980   \n",
       "8          2.380859       0.000000  0.237066                  0.359375   \n",
       "9          1.792647       0.000000  0.164592                  0.270588   \n",
       "10         1.606061       0.071429  0.150587                  0.242424   \n",
       "11         1.432432       0.000000  0.149361                  0.216216   \n",
       "12         1.223077       0.000000  0.130714                  0.184615   \n",
       "13         1.111888       0.000000  0.123988                  0.167832   \n",
       "14         1.000000       0.000000  0.117067                  0.150943   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.583167      0.041667                 0.041667  231.250000   \n",
       "1           0.569966      0.000000                 0.041667 -100.000000   \n",
       "2           0.564126      0.000000                 0.041667 -100.000000   \n",
       "3           0.556246      0.041667                 0.083333  231.250000   \n",
       "4           0.547212      0.000000                 0.083333 -100.000000   \n",
       "5           0.466105      0.208333                 0.291667  231.250000   \n",
       "6           0.430778      0.333333                 0.625000  562.500000   \n",
       "7           0.369667      0.333333                 0.958333  112.000000   \n",
       "8           0.342732      0.000000                 0.958333 -100.000000   \n",
       "9           0.298721      0.000000                 0.958333 -100.000000   \n",
       "10          0.277773      0.041667                 1.000000  -52.678571   \n",
       "11          0.263890      0.000000                 1.000000 -100.000000   \n",
       "12          0.244426      0.000000                 1.000000 -100.000000   \n",
       "13          0.233477      0.000000                 1.000000 -100.000000   \n",
       "14          0.221763      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0        231.250000  \n",
       "1         65.625000  \n",
       "2         32.500000  \n",
       "3         89.285714  \n",
       "4         65.625000  \n",
       "5        157.638889  \n",
       "6        282.211538  \n",
       "7        198.774510  \n",
       "8        138.085938  \n",
       "9         79.264706  \n",
       "10        60.606061  \n",
       "11        43.243243  \n",
       "12        22.307692  \n",
       "13        11.188811  \n",
       "14         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.09003038</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.8724014</td>\n",
       "      <td>0.09534497</td>\n",
       "      <td>0.8055556</td>\n",
       "      <td>0.8064516</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aucpr</td>\n",
       "      <td>0.2601506</td>\n",
       "      <td>0.29980978</td>\n",
       "      <td>0.7482639</td>\n",
       "      <td>0.071428575</td>\n",
       "      <td>0.33333334</td>\n",
       "      <td>0.14772727</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.09003038</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>err_count</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.8809721</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f0point5</td>\n",
       "      <td>0.5944418</td>\n",
       "      <td>0.3485882</td>\n",
       "      <td>0.88709676</td>\n",
       "      <td>0.1724138</td>\n",
       "      <td>0.5555556</td>\n",
       "      <td>0.35714287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.61505747</td>\n",
       "      <td>0.29621416</td>\n",
       "      <td>0.7586207</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.6666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f2</td>\n",
       "      <td>0.68101496</td>\n",
       "      <td>0.2386768</td>\n",
       "      <td>0.6626506</td>\n",
       "      <td>0.45454547</td>\n",
       "      <td>0.8333333</td>\n",
       "      <td>0.45454547</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lift_top_group</td>\n",
       "      <td>6.5555553</td>\n",
       "      <td>13.686525</td>\n",
       "      <td>1.7777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.36044943</td>\n",
       "      <td>0.23865479</td>\n",
       "      <td>0.77814555</td>\n",
       "      <td>0.31771538</td>\n",
       "      <td>0.21953076</td>\n",
       "      <td>0.28969845</td>\n",
       "      <td>0.19715707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.22982079</td>\n",
       "      <td>0.21157269</td>\n",
       "      <td>0.3888889</td>\n",
       "      <td>0.19354838</td>\n",
       "      <td>0.06666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.6041401</td>\n",
       "      <td>0.27104282</td>\n",
       "      <td>0.63828474</td>\n",
       "      <td>0.3394221</td>\n",
       "      <td>0.68313</td>\n",
       "      <td>0.35986376</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.8784229</td>\n",
       "      <td>0.11689511</td>\n",
       "      <td>0.8055556</td>\n",
       "      <td>0.9032258</td>\n",
       "      <td>0.96666664</td>\n",
       "      <td>0.71666664</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.12157706</td>\n",
       "      <td>0.11689511</td>\n",
       "      <td>0.19444445</td>\n",
       "      <td>0.09677419</td>\n",
       "      <td>0.033333335</td>\n",
       "      <td>0.28333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.1082699</td>\n",
       "      <td>0.10367688</td>\n",
       "      <td>0.29083073</td>\n",
       "      <td>0.08565725</td>\n",
       "      <td>0.050291575</td>\n",
       "      <td>0.07453871</td>\n",
       "      <td>0.04003126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pr_auc</td>\n",
       "      <td>0.2601506</td>\n",
       "      <td>0.29980978</td>\n",
       "      <td>0.7482639</td>\n",
       "      <td>0.071428575</td>\n",
       "      <td>0.33333334</td>\n",
       "      <td>0.14772727</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.5952381</td>\n",
       "      <td>0.39050522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14285715</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.33333334</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>r2</td>\n",
       "      <td>-0.48480245</td>\n",
       "      <td>0.7711384</td>\n",
       "      <td>-0.18178834</td>\n",
       "      <td>-1.8294523</td>\n",
       "      <td>0.14169048</td>\n",
       "      <td>-0.27212727</td>\n",
       "      <td>-0.28233477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.82222223</td>\n",
       "      <td>0.24658157</td>\n",
       "      <td>0.6111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.30586272</td>\n",
       "      <td>0.13563693</td>\n",
       "      <td>0.5392872</td>\n",
       "      <td>0.2926726</td>\n",
       "      <td>0.22425783</td>\n",
       "      <td>0.27301776</td>\n",
       "      <td>0.20007814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    mean          sd   cv_1_valid  \\\n",
       "0                  accuracy       0.8875  0.09003038      0.78125   \n",
       "1                       auc    0.8724014  0.09534497    0.8055556   \n",
       "2                     aucpr    0.2601506  0.29980978    0.7482639   \n",
       "3                       err       0.1125  0.09003038      0.21875   \n",
       "4                 err_count          3.6   2.8809721          7.0   \n",
       "5                  f0point5    0.5944418   0.3485882   0.88709676   \n",
       "6                        f1   0.61505747  0.29621416    0.7586207   \n",
       "7                        f2   0.68101496   0.2386768    0.6626506   \n",
       "8            lift_top_group    6.5555553   13.686525    1.7777778   \n",
       "9                   logloss   0.36044943  0.23865479   0.77814555   \n",
       "10      max_per_class_error   0.22982079  0.21157269    0.3888889   \n",
       "11                      mcc    0.6041401  0.27104282   0.63828474   \n",
       "12  mean_per_class_accuracy    0.8784229  0.11689511    0.8055556   \n",
       "13     mean_per_class_error   0.12157706  0.11689511   0.19444445   \n",
       "14                      mse    0.1082699  0.10367688   0.29083073   \n",
       "15                   pr_auc    0.2601506  0.29980978    0.7482639   \n",
       "16                precision    0.5952381  0.39050522          1.0   \n",
       "17                       r2  -0.48480245   0.7711384  -0.18178834   \n",
       "18                   recall   0.82222223  0.24658157    0.6111111   \n",
       "19                     rmse   0.30586272  0.13563693    0.5392872   \n",
       "\n",
       "     cv_2_valid   cv_3_valid   cv_4_valid   cv_5_valid  \n",
       "0        0.8125       0.9375      0.90625          1.0  \n",
       "1     0.8064516         0.95          0.8          1.0  \n",
       "2   0.071428575   0.33333334   0.14772727          0.0  \n",
       "3        0.1875       0.0625      0.09375          0.0  \n",
       "4           6.0          2.0          3.0          0.0  \n",
       "5     0.1724138    0.5555556   0.35714287          1.0  \n",
       "6          0.25    0.6666667          0.4          1.0  \n",
       "7    0.45454547    0.8333333   0.45454547          1.0  \n",
       "8           0.0          0.0          0.0         31.0  \n",
       "9    0.31771538   0.21953076   0.28969845   0.19715707  \n",
       "10   0.19354838   0.06666667          0.5          0.0  \n",
       "11    0.3394221      0.68313   0.35986376          1.0  \n",
       "12    0.9032258   0.96666664   0.71666664          1.0  \n",
       "13   0.09677419  0.033333335   0.28333333          0.0  \n",
       "14   0.08565725  0.050291575   0.07453871   0.04003126  \n",
       "15  0.071428575   0.33333334   0.14772727          0.0  \n",
       "16   0.14285715          0.5   0.33333334          1.0  \n",
       "17   -1.8294523   0.14169048  -0.27212727  -0.28233477  \n",
       "18          1.0          1.0          0.5          1.0  \n",
       "19    0.2926726   0.22425783   0.27301776   0.20007814  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.485 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.849057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.492 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.481111</td>\n",
       "      <td>0.656050</td>\n",
       "      <td>0.882562</td>\n",
       "      <td>0.647821</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.088050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.496 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.463173</td>\n",
       "      <td>0.621973</td>\n",
       "      <td>0.911883</td>\n",
       "      <td>0.710444</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.094340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.501 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.446822</td>\n",
       "      <td>0.591754</td>\n",
       "      <td>0.917438</td>\n",
       "      <td>0.744178</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.506 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.431995</td>\n",
       "      <td>0.564939</td>\n",
       "      <td>0.912809</td>\n",
       "      <td>0.727756</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.081761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.511 sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.417822</td>\n",
       "      <td>0.539771</td>\n",
       "      <td>0.913735</td>\n",
       "      <td>0.735334</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.081761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.516 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.405790</td>\n",
       "      <td>0.518654</td>\n",
       "      <td>0.919599</td>\n",
       "      <td>0.752560</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.081761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.522 sec</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.394182</td>\n",
       "      <td>0.498472</td>\n",
       "      <td>0.919290</td>\n",
       "      <td>0.750756</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.081761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.528 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.383642</td>\n",
       "      <td>0.480286</td>\n",
       "      <td>0.920525</td>\n",
       "      <td>0.757818</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.534 sec</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.374217</td>\n",
       "      <td>0.464044</td>\n",
       "      <td>0.920525</td>\n",
       "      <td>0.757818</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.540 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.366134</td>\n",
       "      <td>0.450075</td>\n",
       "      <td>0.920216</td>\n",
       "      <td>0.755158</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.547 sec</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.358167</td>\n",
       "      <td>0.436335</td>\n",
       "      <td>0.920370</td>\n",
       "      <td>0.756349</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.553 sec</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.351189</td>\n",
       "      <td>0.424246</td>\n",
       "      <td>0.919444</td>\n",
       "      <td>0.753540</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.081761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.560 sec</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.344963</td>\n",
       "      <td>0.413352</td>\n",
       "      <td>0.935957</td>\n",
       "      <td>0.764871</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.571 sec</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.339390</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.935648</td>\n",
       "      <td>0.761612</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.081761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.582 sec</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.334128</td>\n",
       "      <td>0.394222</td>\n",
       "      <td>0.937191</td>\n",
       "      <td>0.764170</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.594 sec</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.329475</td>\n",
       "      <td>0.385865</td>\n",
       "      <td>0.937809</td>\n",
       "      <td>0.765383</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.606 sec</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.324791</td>\n",
       "      <td>0.377478</td>\n",
       "      <td>0.937191</td>\n",
       "      <td>0.763185</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.081761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.618 sec</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.320779</td>\n",
       "      <td>0.370115</td>\n",
       "      <td>0.937809</td>\n",
       "      <td>0.765383</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-30 22:17:02</td>\n",
       "      <td>36.629 sec</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.317055</td>\n",
       "      <td>0.363257</td>\n",
       "      <td>0.953395</td>\n",
       "      <td>0.770929</td>\n",
       "      <td>6.625</td>\n",
       "      <td>0.075472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2020-01-30 22:17:02  36.485 sec              0.0       0.500000   \n",
       "1     2020-01-30 22:17:02  36.492 sec              5.0       0.481111   \n",
       "2     2020-01-30 22:17:02  36.496 sec             10.0       0.463173   \n",
       "3     2020-01-30 22:17:02  36.501 sec             15.0       0.446822   \n",
       "4     2020-01-30 22:17:02  36.506 sec             20.0       0.431995   \n",
       "5     2020-01-30 22:17:02  36.511 sec             25.0       0.417822   \n",
       "6     2020-01-30 22:17:02  36.516 sec             30.0       0.405790   \n",
       "7     2020-01-30 22:17:02  36.522 sec             35.0       0.394182   \n",
       "8     2020-01-30 22:17:02  36.528 sec             40.0       0.383642   \n",
       "9     2020-01-30 22:17:02  36.534 sec             45.0       0.374217   \n",
       "10    2020-01-30 22:17:02  36.540 sec             50.0       0.366134   \n",
       "11    2020-01-30 22:17:02  36.547 sec             55.0       0.358167   \n",
       "12    2020-01-30 22:17:02  36.553 sec             60.0       0.351189   \n",
       "13    2020-01-30 22:17:02  36.560 sec             65.0       0.344963   \n",
       "14    2020-01-30 22:17:02  36.571 sec             70.0       0.339390   \n",
       "15    2020-01-30 22:17:02  36.582 sec             75.0       0.334128   \n",
       "16    2020-01-30 22:17:02  36.594 sec             80.0       0.329475   \n",
       "17    2020-01-30 22:17:02  36.606 sec             85.0       0.324791   \n",
       "18    2020-01-30 22:17:02  36.618 sec             90.0       0.320779   \n",
       "19    2020-01-30 22:17:02  36.629 sec             95.0       0.317055   \n",
       "\n",
       "    training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0           0.693147      0.500000         0.000000          1.000   \n",
       "1           0.656050      0.882562         0.647821          6.625   \n",
       "2           0.621973      0.911883         0.710444          6.625   \n",
       "3           0.591754      0.917438         0.744178          6.625   \n",
       "4           0.564939      0.912809         0.727756          6.625   \n",
       "5           0.539771      0.913735         0.735334          6.625   \n",
       "6           0.518654      0.919599         0.752560          6.625   \n",
       "7           0.498472      0.919290         0.750756          6.625   \n",
       "8           0.480286      0.920525         0.757818          6.625   \n",
       "9           0.464044      0.920525         0.757818          6.625   \n",
       "10          0.450075      0.920216         0.755158          6.625   \n",
       "11          0.436335      0.920370         0.756349          6.625   \n",
       "12          0.424246      0.919444         0.753540          6.625   \n",
       "13          0.413352      0.935957         0.764871          6.625   \n",
       "14          0.403552      0.935648         0.761612          6.625   \n",
       "15          0.394222      0.937191         0.764170          6.625   \n",
       "16          0.385865      0.937809         0.765383          6.625   \n",
       "17          0.377478      0.937191         0.763185          6.625   \n",
       "18          0.370115      0.937809         0.765383          6.625   \n",
       "19          0.363257      0.953395         0.770929          6.625   \n",
       "\n",
       "    training_classification_error  \n",
       "0                        0.849057  \n",
       "1                        0.088050  \n",
       "2                        0.094340  \n",
       "3                        0.075472  \n",
       "4                        0.081761  \n",
       "5                        0.081761  \n",
       "6                        0.081761  \n",
       "7                        0.081761  \n",
       "8                        0.075472  \n",
       "9                        0.075472  \n",
       "10                       0.075472  \n",
       "11                       0.075472  \n",
       "12                       0.081761  \n",
       "13                       0.075472  \n",
       "14                       0.081761  \n",
       "15                       0.075472  \n",
       "16                       0.075472  \n",
       "17                       0.081761  \n",
       "18                       0.075472  \n",
       "19                       0.075472  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>winner_pga</td>\n",
       "      <td>151.066833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.445544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>winner_dga</td>\n",
       "      <td>114.597305</td>\n",
       "      <td>0.758587</td>\n",
       "      <td>0.337983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>winner_sag</td>\n",
       "      <td>29.370192</td>\n",
       "      <td>0.194419</td>\n",
       "      <td>0.086622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nominations</td>\n",
       "      <td>19.300804</td>\n",
       "      <td>0.127763</td>\n",
       "      <td>0.056924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year</td>\n",
       "      <td>8.320313</td>\n",
       "      <td>0.055077</td>\n",
       "      <td>0.024539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nom_sag</td>\n",
       "      <td>6.095071</td>\n",
       "      <td>0.040347</td>\n",
       "      <td>0.017976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>winner_bafta</td>\n",
       "      <td>4.053117</td>\n",
       "      <td>0.026830</td>\n",
       "      <td>0.011954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>winner_gg_drama</td>\n",
       "      <td>2.857199</td>\n",
       "      <td>0.018913</td>\n",
       "      <td>0.008427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nom_bafta</td>\n",
       "      <td>2.735089</td>\n",
       "      <td>0.018105</td>\n",
       "      <td>0.008067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nom_dga</td>\n",
       "      <td>0.468218</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.001381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nom_pga</td>\n",
       "      <td>0.122533</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>winner_gg_comedy</td>\n",
       "      <td>0.049229</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nom_cannes</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nom_gg_comedy</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nom_gg_drama</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            variable  relative_importance  scaled_importance  percentage\n",
       "0         winner_pga           151.066833           1.000000    0.445544\n",
       "1         winner_dga           114.597305           0.758587    0.337983\n",
       "2         winner_sag            29.370192           0.194419    0.086622\n",
       "3        Nominations            19.300804           0.127763    0.056924\n",
       "4               year             8.320313           0.055077    0.024539\n",
       "5            nom_sag             6.095071           0.040347    0.017976\n",
       "6       winner_bafta             4.053117           0.026830    0.011954\n",
       "7    winner_gg_drama             2.857199           0.018913    0.008427\n",
       "8          nom_bafta             2.735089           0.018105    0.008067\n",
       "9            nom_dga             0.468218           0.003099    0.001381\n",
       "10           nom_pga             0.122533           0.000811    0.000361\n",
       "11  winner_gg_comedy             0.049229           0.000326    0.000145\n",
       "12        nom_cannes             0.014549           0.000096    0.000043\n",
       "13     nom_gg_comedy             0.008317           0.000055    0.000025\n",
       "14      nom_gg_drama             0.003115           0.000021    0.000009"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model = aml.leader\n",
    "top_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2019's films\n",
    "test = full_table.loc[(full_table['year'] == 2019)]\n",
    "\n",
    "# Import a binary outcome train/test set into H2O\n",
    "test = h2o.H2OFrame(test)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872341</td><td style=\"text-align: right;\">0.127659</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871212</td><td style=\"text-align: right;\">0.128788</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871916</td><td style=\"text-align: right;\">0.128084</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871639</td><td style=\"text-align: right;\">0.128361</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872341</td><td style=\"text-align: right;\">0.127659</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872341</td><td style=\"text-align: right;\">0.127659</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.508026</td><td style=\"text-align: right;\">0.491974</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.871212</td><td style=\"text-align: right;\">0.128788</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.805078</td><td style=\"text-align: right;\">0.194922</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = top_model.predict(test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = preds['predict']\n",
    "test['probA'] = preds['p1']\n",
    "test_pd = test.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film</th>\n",
       "      <th>probA</th>\n",
       "      <th>%_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1917 (2019 film)</td>\n",
       "      <td>0.491974</td>\n",
       "      <td>31.061029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parasite (2019 film)</td>\n",
       "      <td>0.194922</td>\n",
       "      <td>12.306475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Irishman</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>8.131125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Once Upon a Time in Hollywood</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>8.131125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joker (2019 film)</td>\n",
       "      <td>0.128361</td>\n",
       "      <td>8.104137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jojo Rabbit</td>\n",
       "      <td>0.128084</td>\n",
       "      <td>8.086673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ford v Ferrari</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>8.059812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Women (2019 film)</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>8.059812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Marriage Story</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>8.059812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            film     probA  %_confidence\n",
       "6               1917 (2019 film)  0.491974     31.061029\n",
       "8           Parasite (2019 film)  0.194922     12.306475\n",
       "1                   The Irishman  0.128788      8.131125\n",
       "7  Once Upon a Time in Hollywood  0.128788      8.131125\n",
       "3              Joker (2019 film)  0.128361      8.104137\n",
       "2                    Jojo Rabbit  0.128084      8.086673\n",
       "0                 Ford v Ferrari  0.127659      8.059812\n",
       "4       Little Women (2019 film)  0.127659      8.059812\n",
       "5                 Marriage Story  0.127659      8.059812"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rankings = test_pd[['film','probA']].sort_values('probA', ascending = False)\n",
    "final_rankings['%_confidence'] = final_rankings['probA']/final_rankings['probA'].sum() * 100\n",
    "final_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the Oscar goes to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the Oscar goes to...\n",
      "🎉🏆1917🏆🎉\n"
     ]
    }
   ],
   "source": [
    "bp_winner = np.array(final_rankings.reset_index())[0][1].split('(')[0].strip()\n",
    "print(f'And the Oscar goes to...\\n🎉🏆{bp_winner}🏆🎉')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
